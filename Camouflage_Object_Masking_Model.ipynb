{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31e0c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1aa9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a39bbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataUpload:\n",
    "    \n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.image_path = images_path\n",
    "        self.mask_path = masks_path\n",
    "        self.images_array, self.masks_array = [], []\n",
    "    \n",
    "    def loadData(self):\n",
    "        for i in tqdm(os.listdir(self.image_path)):\n",
    "            image = os.path.join(self.image_path, i)\n",
    "            image = cv.imread(image)\n",
    "            \n",
    "            self.images_array.append(image)\n",
    "        \n",
    "        for m in tqdm(os.listdir(self.mask_path)):\n",
    "            mask = os.path.join(self.mask_path, m)\n",
    "            mask = cv.imread(mask)\n",
    "            \n",
    "            self.masks_array.append(mask)\n",
    "        \n",
    "        return self.images_array, self.masks_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74042c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allAboutData(train_images_path, train_masks_path, val_images_path, val_masks_path, val_fraction=0.6):\n",
    "    \n",
    "    trainLoader = dataUpload(train_images_path, train_masks_path)\n",
    "    train_images, train_masks = trainLoader.loadData()\n",
    "    \n",
    "    val_testLoader = dataUpload(val_test_images_path, val_test_masks_path)\n",
    "    val_test_images, val_test_masks = val_testLoader.loadData()\n",
    "    \n",
    "    def val_test_split(val_fraction):\n",
    "        val_test_zip = [[image, mask] for image, mask in zip(val_test_images, val_test_masks)]\n",
    "        \n",
    "        val_size = int(val_fraction * len(val_test_zip))\n",
    "        test_size = len(val_test_zip) - val_size\n",
    "        valset, testset = torch.utils.data.random_split(val_test_zip, (val_size, test_size), generator=torch.Generator().manual_seed(0))\n",
    "        \n",
    "        val_images, val_masks = [], []\n",
    "        test_images, test_masks = [], []\n",
    "\n",
    "        for val_elem in valset:\n",
    "\n",
    "            val_images.append(val_elem[0])\n",
    "            val_masks.append(val_elem[1])\n",
    "        \n",
    "        for test_elem in testset:\n",
    "\n",
    "            test_images.append(test_elem[0])\n",
    "            test_masks.append(test_elem[1])\n",
    "        \n",
    "        return val_images, val_masks, test_images, test_masks\n",
    "    \n",
    "    val_images, val_masks, test_images, test_masks = val_test_split(val_fraction)\n",
    "    return train_images, train_masks, val_images, val_masks, test_images, test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2633f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImages(images, masks, height, width):\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        images[i] = cv.resize(images[i], (width, height))\n",
    "        masks[i] = cv.resize(masks[i], (width, height))\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "def toGrayScale(images, masks):\n",
    "    gray_images, gray_masks = [], []\n",
    "    for image, mask in zip(images, masks):\n",
    "        gray_images.append(cv.cvtColor(image, cv.COLOR_BGR2GRAY))\n",
    "        gray_masks.append(cv.cvtColor(mask, cv.COLOR_BGR2GRAY))\n",
    "    \n",
    "    return gray_images, gray_masks\n",
    "\n",
    "def augmentImages(images, masks, translate, rotate):\n",
    "    if translate:\n",
    "        images, masks = translateData(images, masks)\n",
    "    if rotate:\n",
    "        images, masks = rotateData(images, masks)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "def translateData(images, masks):\n",
    "    translated_images, translated_masks = [], []\n",
    "    \n",
    "    for image, mask in zip(images, masks):\n",
    "        translated_img, translated_mask = translateImage(image, mask)\n",
    "        translated_images.append(translated_img)\n",
    "        translated_masks.append(translated_mask)\n",
    "    \n",
    "    return images + translated_images, masks + translated_masks\n",
    "\n",
    "def rotateData(images, masks):\n",
    "    rotated_images, rotated_masks = [], []\n",
    "    \n",
    "    for image, mask in zip(images, masks):\n",
    "        rot_img, rot_mask = rotateImage(image, mask)\n",
    "        rotated_images.append(rot_img)\n",
    "        rotated_masks.append(rot_mask)\n",
    "    \n",
    "    return images + rotated_images, masks + rotated_masks\n",
    "\n",
    "def translateImage(image, mask):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    translate_value = np.random.rand() / 2\n",
    "    width_translate, height_translate = width * translate_value, height * translate_value\n",
    "    tx, ty = width / width_translate, height / height_translate\n",
    "    translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)\n",
    "    \n",
    "    translated_image = cv.warpAffine(src=image, M=translation_matrix, dsize=(width, height))\n",
    "    translated_mask = cv.warpAffine(src=mask, M=translation_matrix, dsize=(width, height))\n",
    "    \n",
    "    return translated_image, translated_mask\n",
    "\n",
    "def rotateImage(image, mask):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    center = (width/2, height/2)\n",
    "    angle = np.random.rand() * 90\n",
    "    rotate_matrix = cv.getRotationMatrix2D(center=center, angle=angle, scale=1)\n",
    "    \n",
    "    rotated_image = cv.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))\n",
    "    rotated_mask = cv.warpAffine(src=mask, M=rotate_matrix, dsize=(width, height))\n",
    "    \n",
    "    return rotated_image, rotated_mask\n",
    "\n",
    "def scaleValues(images, masks):\n",
    "    return images / 255.0, masks / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dd4883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(images, masks, height, width, augment=False, translate=False, rotate=False):\n",
    "    images, masks = resizeImages(images, masks, height, width)\n",
    "    num_channels = 1\n",
    "    \n",
    "    images, masks = toGrayScale(images, masks)\n",
    "    \n",
    "    if augment:\n",
    "        images, masks = augmentImages(images, masks, translate, rotate)\n",
    "    \n",
    "    images, masks = np.array(images, dtype=np.float32), np.array(masks, dtype=np.float32)\n",
    "    images /= 255.0\n",
    "    masks /= 255.0\n",
    "    return images, masks, num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fb4b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(images, masks, batch_size, shuffle=True, train=True):\n",
    "    X, Y = images, masks\n",
    "    \n",
    "    index = 0\n",
    "    num_images = len(images)\n",
    "    indices = [*range(num_images)]\n",
    "    if shuffle:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    while True:\n",
    "        if index >= num_images:\n",
    "            index = 0\n",
    "            if shuffle:\n",
    "                random.shuffle(indices)\n",
    "        index += 1\n",
    "        \n",
    "        for i in range(0, num_images, batch_size):\n",
    "            try:\n",
    "                x = X[indices[i:i+batch_size]]\n",
    "                y = Y[indices[i:i+batch_size]]\n",
    "            except:\n",
    "                x = X[indices[i:]]\n",
    "                y = Y[indices[i:]]\n",
    "            \n",
    "            if len(x) != batch_size or i == num_images - batch_size:\n",
    "                yield x, y, 1\n",
    "            else:\n",
    "                yield x, y, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22e1bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x.float()))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86694f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_layer = convBlock(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7d87ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convTranspose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_layer = convBlock(out_channels * 2, out_channels)\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.convTranspose(x)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a05ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encode1 = encoderBlock(1, 32)\n",
    "        self.encode2 = encoderBlock(32, 64)\n",
    "        self.encode3 = encoderBlock(64, 128)\n",
    "        self.encode4 = encoderBlock(128, 256)\n",
    "        \n",
    "        self.bottleneck = convBlock(256, 512)\n",
    "        \n",
    "        self.decode1 = decoderBlock(512, 256)\n",
    "        self.decode2 = decoderBlock(256, 128)\n",
    "        self.decode3 = decoderBlock(128, 64)\n",
    "        self.decode4 = decoderBlock(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.classify = nn.Conv2d(32, 1, kernel_size=1, padding=0)\n",
    "        self.float()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, p1 = self.encode1(x)\n",
    "        x2, p2 = self.encode2(p1)\n",
    "        x3, p3 = self.encode3(p2)\n",
    "        x4, p4 = self.encode4(p3)\n",
    "        \n",
    "        b = self.bottleneck(p4)\n",
    "        \n",
    "        d1 = self.decode1(b, x4)\n",
    "        d2 = self.decode2(d1, x3)\n",
    "        d3 = self.decode3(d2, x2)\n",
    "        d4 = self.decode4(d3, x1)\n",
    "        \n",
    "        output = self.classify(d4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9144d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelDefinition(model_class=U_Net, learning_rate=0.001, pretrained=True, schedule=True):\n",
    "    if pretrained:\n",
    "        model = smp.FPN(encoder_weights='imagenet', in_channels=1).to(device)\n",
    "    else:\n",
    "        model = model_class().to(device)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if schedule:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=30, cooldown=10)\n",
    "        return model, loss_fn, optimizer, scheduler\n",
    "    else:\n",
    "        return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d53dea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler=None):\n",
    "    train_loss, val_loss = [], []\n",
    "    train_DS, val_DS = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss, num_images, dice_score = 0, 0, 0\n",
    "        \n",
    "        while True:\n",
    "            X, Y, count = next(train_generator)\n",
    "            X = torch.tensor(X)\n",
    "            Y = torch.tensor(Y)\n",
    "            \n",
    "            X = torch.reshape(X, (-1, 1, height, width)).to(device)\n",
    "            Y = torch.reshape(Y, (-1, 1, height, width)).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sigmoided_output = sigmoid(output)\n",
    "            dice_score += diceScore(sigmoided_output, Y).item()\n",
    "            \n",
    "            loss = loss_fn(output, Y)\n",
    "            epoch_loss += X.size(dim=0) * loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                       \n",
    "            num_images += X.size(dim=0)            \n",
    "            if count == 1:\n",
    "                break\n",
    "        print(f\"Loss After {epoch + 1} Epochs: {epoch_loss / num_images: .6f}\")\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch_loss/num_images)\n",
    "        val_generator = dataGenerator(val_images, val_masks, val_batch_size, shuffle=False, train=False)\n",
    "        valset_loss, valset_dice_score = valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=True)\n",
    "        \n",
    "        train_loss.append(epoch_loss / num_images)\n",
    "        train_DS.append(dice_score / num_images)\n",
    "        val_loss.append(valset_loss)\n",
    "        val_DS.append(valset_dice_score)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\FPN_With_Calculated_Scheduling\\FPN_GRAY_' + str(epoch+1) + '_Epochs_BCEWithLogits.pt')\n",
    "    \n",
    "    return model, train_loss, train_DS, val_loss, val_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cddce024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=False):\n",
    "    Y_pred = []\n",
    "    num_images, loss, dice_score = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            X, Y, count = next(val_generator)\n",
    "            \n",
    "            X = torch.tensor(X)\n",
    "            X = torch.reshape(X, (-1, 1, height, width)).to(device)\n",
    "            Y = torch.tensor(Y)\n",
    "            Y = torch.reshape(Y, (-1, 1, height, width)).to(device)\n",
    "            \n",
    "            Y_output = model(X)\n",
    "            num_images += X.size(dim=0)\n",
    "            loss += loss_fn(Y_output, Y).item() * X.size(dim=0)\n",
    "            \n",
    "            Y_output = torch.reshape(Y_output, (-1, height, width, 1))\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            Y_output = sigmoid(Y_output)\n",
    "            dice_score += diceScore(Y_output, Y)\n",
    "            \n",
    "            Y_pred += list(np.reshape(Y_output.detach().cpu().numpy(), (-1, height, width)))\n",
    "            \n",
    "            if count == 1:\n",
    "                break\n",
    "    \n",
    "    if called_by_train:\n",
    "        return loss / num_images, dice_score / num_images\n",
    "    else:\n",
    "        return Y_pred, dice_score / num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "325c4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceScore(Y_output, Y):\n",
    "    gamma = 1\n",
    "    batch_size = Y_output.size(dim=0)\n",
    "    \n",
    "    model_outputs = Y_output.reshape(batch_size, -1).float()\n",
    "    original_outputs = Y.reshape(batch_size, -1).float()\n",
    "    intersection = (model_outputs * original_outputs).sum().float()\n",
    "\n",
    "    return batch_size * (2 * intersection + gamma) / (model_outputs.sum() + original_outputs.sum() + gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ea41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayOutputs(val_images, val_masks, Y_pred, num_show):\n",
    "    num_images = len(val_images)\n",
    "    indices = np.random.randint(0, num_images, size=num_show)\n",
    "    \n",
    "    for index in range(len(indices)):\n",
    "        cv.imshow('Grayscale Image', cv.resize(val_images[index], (256, 256)))\n",
    "        \n",
    "        cv.imshow('Original Mask', cv.resize(val_masks[index], (256, 256)))\n",
    "        cv.moveWindow('Original Mask', 300, 0)\n",
    "        \n",
    "        cv.imshow('Predicted Mask', cv.resize((Y_pred[index] * 255).astype(np.uint8), (256, 256)))\n",
    "        cv.moveWindow('Predicted Mask', 300, 300)\n",
    "        cv.waitKey(2000)\n",
    "    \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e2c0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\Images\\Train'\n",
    "train_masks_path = r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\Masks\\Train'\n",
    "\n",
    "val_test_images_path = r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\Images\\Validation'\n",
    "val_test_masks_path = r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\Masks\\Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af912e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 64, 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 200\n",
    "\n",
    "train_batch_size, val_batch_size, test_batch_size = 16, 8, 8\n",
    "val_fraction = 1.0\n",
    "shuffle = True\n",
    "\n",
    "augment = True\n",
    "translate, rotate = True, True\n",
    "\n",
    "num_show = 10\n",
    "pretrain = True\n",
    "schedule = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e66350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:06<00:00, 129.44it/s]\n",
      "100%|██████████| 800/800 [00:08<00:00, 98.77it/s] \n",
      "100%|██████████| 200/200 [00:01<00:00, 163.66it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 99.95it/s] \n"
     ]
    }
   ],
   "source": [
    "train_images, train_masks, val_images, val_masks, test_images, test_masks = allAboutData(train_images_path, train_masks_path, val_test_images_path, val_test_masks_path, val_fraction=val_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19047411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_masks, train_num_channels = preProcess(train_images, train_masks, height, width, augment=augment, translate=translate, rotate=rotate)\n",
    "val_images, val_masks, val_num_channels = preProcess(val_images, val_masks, height, width)\n",
    "test_images, test_masks, test_num_channels = preProcess(test_images, test_masks, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5dc3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = dataGenerator(train_images, train_masks, train_batch_size, shuffle=shuffle, train=True)\n",
    "val_generator = dataGenerator(val_images, val_masks, val_batch_size, shuffle=False, train=False)\n",
    "test_generator = dataGenerator(test_images, test_masks, test_batch_size, shuffle=False, train=False)\n",
    "valUsingTrain_generator = dataGenerator(train_images, train_masks, val_batch_size, shuffle=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42052943",
   "metadata": {},
   "outputs": [],
   "source": [
    "if schedule:\n",
    "    model, loss_fn, optimizer, scheduler = modelDefinition(model_class=U_Net, learning_rate=learning_rate, pretrained=pretrain, schedule=schedule)\n",
    "else:\n",
    "    model, loss_fn, optimizer = modelDefinition(model_class=U_Net, learning_rate=learning_rate, pretrained=pretrain, schedule=schedule)\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93435a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPN(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): FPNDecoder(\n",
      "    (p5): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p4): FPNBlock(\n",
      "      (skip_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (p3): FPNBlock(\n",
      "      (skip_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (p2): FPNBlock(\n",
      "      (skip_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (seg_blocks): ModuleList(\n",
      "      (0): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (merge): MergeBlock()\n",
      "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode=bilinear)\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ") <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001868CA8D8D0>\n"
     ]
    }
   ],
   "source": [
    "print(model, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0c61665",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, train_loss, train_DS, val_loss, val_DS \u001b[39m=\u001b[39m trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, train_num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler)\n",
      "Cell \u001b[1;32mIn [29], line 26\u001b[0m, in \u001b[0;36mtrainingLoop\u001b[1;34m(train_generator, model, loss_fn, optimizer, num_epochs, height, width, num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler)\u001b[0m\n\u001b[0;32m     23\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, Y)\n\u001b[0;32m     24\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m*\u001b[39m loss\n\u001b[1;32m---> 26\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     27\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     29\u001b[0m num_images \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)            \n",
      "File \u001b[1;32mc:\\Users\\anany\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\anany\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, train_loss, train_DS, val_loss, val_DS = trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, train_num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e5229ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(train_loss))]\n\u001b[0;32m      2\u001b[0m val_DS \u001b[39m=\u001b[39m [val_DS[i] \u001b[39m*\u001b[39m val_batch_size \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(val_DS))]\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(X, val_DS)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "val_DS = [val_DS[i] * val_batch_size for i in range(len(val_DS))]\n",
    "plt.plot(X, val_DS)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Dice Score')\n",
    "plt.savefig(r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\FPN_With_Calculated_Scheduling\\Val_DS_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "train_DS = [train_DS[i] * train_batch_size for i in range(len(train_DS))]\n",
    "plt.plot(X, train_DS)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Train Dice Score')\n",
    "plt.savefig(r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\FPN_With_Calculated_Scheduling\\Train_DS_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd903a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, train_loss)\n",
    "plt.plot(X, val_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend((['Train Loss', 'Val Loss']))\n",
    "plt.savefig(r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\FPN_With_Calculated_Scheduling\\Train_Val_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, val_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.savefig(r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\FPN_With_Calculated_Scheduling\\Val_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, train_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.savefig(r'C:\\Users\\anany\\OneDrive\\Documents\\GitHub\\WiDS-2022-Camouflage-Object-Masking\\FPN_With_Calculated_Scheduling\\Train_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_DS, val_loss, val_DS = fixLists(train_loss), fixLists(train_DS), fixLists(val_loss), fixLists(val_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixLists(input_list):\n",
    "    fixed_list = []\n",
    "    for elem in input_list:\n",
    "        try:\n",
    "            fixed_list.append(elem.detach().cpu().item())\n",
    "        except:\n",
    "            fixed_list.append(elem)\n",
    "    return fixed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736eb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred, dice_score = valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd15a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayOutputs(val_images, val_masks, Y_pred, num_show=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "670b387f3e3b322b29e4adea29f11b6f78e42497539abca64085771265e0cc4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
